{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Mathematics\n",
    "# Simple Linear Regression\n",
    "# In-Class Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to your class handout for background information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "submarine_sightings = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "cyber_activity_metric = np.array([0.021025,0.022103,0.023237,0.024428,0.025681,0.026997,0.028381,0.029836,0.031366,0.032974])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate our regression values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(submarine_sightings,cyber_activity_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.001324557575757576,\n",
       " 0.019317733333333337,\n",
       " 0.9980126947882119,\n",
       " 6.807697897873586e-11,\n",
       " 2.9567948236252566e-05)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope, intercept, r_value, p_value, std_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, print the R^2 value.  How good is your fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.9960293389584285\n"
     ]
    }
   ],
   "source": [
    "print('r-squared:', r_value**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "a) correlation coefficient = r_value = .998\n",
    "\n",
    "b) alpha_hat = intercept = .019, beta_hat = slope = .0013\n",
    "\n",
    "c) as observed from the correlation coefficient being close to 1, these two variables do demonstrate a linear relationship. \n",
    "\n",
    "d) based on the linear relationship between the number of submarine sightings and the cyber activity metric, the two observations are correlated. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "[0.8, 4.0, 16.64]\n",
      "\n",
      "\n",
      "Step 1\n",
      "[0.64, 3.2, 10.65]\n",
      "\n",
      "\n",
      "Step 2\n",
      "[0.51, 2.56, 6.81]\n",
      "\n",
      "\n",
      "Step 3\n",
      "[0.41, 2.05, 4.37]\n",
      "\n",
      "\n",
      "Step 4\n",
      "[0.33, 1.64, 2.8]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = 0.1\n",
    "pos = [1,5,26] #f(m,b) = x**b + y**b)\n",
    "for i in range(5):\n",
    "    pos[0] = round((pos[0] - (step * 2 * pos[0])),2)\n",
    "    pos[1] = round((pos[1] - (step * 2 * pos[1])),2)\n",
    "    pos[2] = round((pos[0]**2 + pos[1]**2),2)\n",
    "    \n",
    "    print(\"Step {}\".format(i))\n",
    "    print (pos)\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "[0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "Step 1\n",
      "[0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "Step 2\n",
      "[0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "Step 3\n",
      "[0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "Step 4\n",
      "[0.0, 0.0, 0.0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = 0.5\n",
    "pos = [1,5,26] #f(m,b) = x**b + y**b)\n",
    "for i in range(5):\n",
    "    pos[0] = round((pos[0] - (step * 2 * pos[0])),2)\n",
    "    pos[1] = round((pos[1] - (step * 2 * pos[1])),2)\n",
    "    pos[2] = round((pos[0]**2 + pos[1]**2),2)\n",
    "    \n",
    "    print(\"Step {}\".format(i))\n",
    "    print (pos)\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now save your output.  Go to File -> Print Preview and save your final output as a PDF.  Turn in to your Instructor, along with any additional sheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 \n",
    "a) with a learning rate of .1 and only 5 steps, the model begins to converge, but does not have enough time arrive at the local minima. \n",
    "\n",
    "b) with a learning rate of .5, the model converges immediately due to it's relationship with the partial derivatives of the original loss function. \n",
    "\n",
    "c) In this case, the ideal learning rate is .5. This may not always be the case. A learning rate that is too large may miss the local optima, while a learning rate that is too small may take too long to converge on the local optima, as demonstrated in part a) of this problem. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
